{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArvindReddyC/Sord_analysis/blob/main/Notebooks/CCN_activity_recog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evP10kKOFAMi",
        "outputId": "6769fe70-39a8-4916-df66-483481997ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sord_analysis'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 174 (delta 70), reused 123 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (174/174), 59.26 MiB | 19.28 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ArvindReddyC/Sord_analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzL5Em0OWisN"
      },
      "outputs": [],
      "source": [
        "!touch test.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d1uIbGJFIvb",
        "outputId": "92bcac6f-f335-49c6-d5c3-f4363c51de94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_PERaPvFUlN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import plotly.express as px \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9aqw5aqFhlV"
      },
      "outputs": [],
      "source": [
        "main_df  = pd.read_csv('/content/drive/MyDrive/sord_data/raw_training_df.csv' , index_col = 0)\n",
        "main_df.sort_values( ['User_Id','Time'], inplace=True )\n",
        "main_df.reset_index( drop=True , inplace= True )\n",
        "main_df.columns = [ 'Time' , \t'Angle' , 'ax' , 'ay' , 'az' , 'gx' , 'gy' , 'gz' , 'mx' , 'my' , 'mz' , 'Activity' , \t'User_Id'  ]\n",
        "main_df['Activity'] = main_df['Activity'].map( { 'Sitting':0  , 'Standing' : 1 , 'Walking' : 2   } )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1CraEm4Gkel",
        "outputId": "a256175b-d37c-4ed2-e7d0-89f4266dbf9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37118, 64, 10)\n",
            "(37118,)\n",
            " X_train : (27838, 64, 10) \n",
            " X_test : (9280, 64, 10) \n",
            " y_train : (27838, 3) \n",
            " y_test : (9280, 3)  \n"
          ]
        }
      ],
      "source": [
        "from scipy import stats\n",
        "\n",
        "def create_segments_and_labels(df, time_steps, step):\n",
        "    N_FEATURES = 10\n",
        "    segments = []\n",
        "    labels = []\n",
        "    for i in range(0, len(df) - time_steps, step):\n",
        "        angle = df['Angle'].values[i: i + time_steps]\n",
        "        ax = df['ax'].values[i: i + time_steps]\n",
        "        ay = df['ay'].values[i: i + time_steps]\n",
        "        az = df['az'].values[i: i + time_steps]\n",
        "        gx = df['gx'].values[i: i + time_steps]\n",
        "        gy=  df['gy'].values[i: i + time_steps]\n",
        "        gz=  df['gz'].values[i: i + time_steps]\n",
        "        mx =  df['mx'].values[i: i + time_steps]\n",
        "        my = df['my'].values[i: i + time_steps]\n",
        "        mz  = df['mz'].values[i: i + time_steps]\n",
        "        # Retrieve the most often used label in this segment\n",
        "        labels.append( stats.mode(df['Activity'][i: i + time_steps])[0][0] ) \n",
        "        segments.append([angle, ax , ay , az , gx , gy , gz , mx , my , mz ])\n",
        "    # Bring the segments into a better shape\n",
        "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
        "    label = np.asarray(labels)\n",
        "    return (reshaped_segments,label)\n",
        "\n",
        "reshaped_x , labels   =  create_segments_and_labels(main_df, 64 , 32)\n",
        "print(reshaped_x.shape)\n",
        "print( labels.shape )\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( reshaped_x , labels , test_size=0.25, random_state=42)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print( f' X_train : {X_train.shape} \\n X_test : {X_test.shape} \\n y_train : {y_train.shape} \\n y_test : {y_test.shape}  ' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "47sv3uIlIJID",
        "outputId": "ee17d7f4-9156-4c68-da94-9ec1d9bcc3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">p=False #1: 99.806\n",
            "[[99.80603456497192]] [False]\n",
            "Param=False: 99.806% (+/-0.000)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# cnn model with standardization\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "\n",
        "\n",
        "# standardize data\n",
        "def scale_data(trainX, testX, standardize):\n",
        "\t# remove overlap\n",
        "\tcut = int(trainX.shape[1] / 2)\n",
        "\tlongX = trainX[:, -cut:, :]\n",
        "\t# flatten windows\n",
        "\tlongX = longX.reshape((longX.shape[0] * longX.shape[1], longX.shape[2]))\n",
        "\t# flatten train and test\n",
        "\tflatTrainX = trainX.reshape((trainX.shape[0] * trainX.shape[1], trainX.shape[2]))\n",
        "\tflatTestX = testX.reshape((testX.shape[0] * testX.shape[1], testX.shape[2]))\n",
        "\t# standardize\n",
        "\tif standardize:\n",
        "\t\ts = StandardScaler()\n",
        "\t\t# fit on training data\n",
        "\t\ts.fit(longX)\n",
        "\t\t# apply to training and test data\n",
        "\t\tlongX = s.transform(longX)\n",
        "\t\tflatTrainX = s.transform(flatTrainX)\n",
        "\t\tflatTestX = s.transform(flatTestX)\n",
        "\t# reshape\n",
        "\tflatTrainX = flatTrainX.reshape((trainX.shape))\n",
        "\tflatTestX = flatTestX.reshape((testX.shape))\n",
        "\treturn flatTrainX, flatTestX\n",
        "\n",
        "def evaluate_model(trainX, trainy, testX, testy, param):\n",
        "\tverbose, epochs, batch_size = 0, 10, 32\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\t# scale data\n",
        "\ttrainX, testX = scale_data(trainX, testX, param)\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(MaxPooling1D(pool_size=2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "\treturn accuracy,model\n",
        " \n",
        "# summarize scores\n",
        "def summarize_results(scores, params):\n",
        "\tprint(scores, params)\n",
        "\t# summarize mean and standard deviation\n",
        "\tfor i in range(len(scores)):\n",
        "\t\tm, s = mean(scores[i]), std(scores[i])\n",
        "\t\tprint('Param=%s: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
        "\t# boxplot of scores\n",
        "\tpyplot.boxplot(scores, labels=params)\n",
        "\tpyplot.savefig('exp_cnn_standardize')\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(params = [False] ,   repeats=1):\n",
        "\t# load data\n",
        "\tmy_model = []\n",
        "\ttrainX, trainy, testX, testy = X_train, y_train , X_test , y_test\n",
        "\t# test each parameter\n",
        "\tall_scores = list()\n",
        "\tfor p in params:\n",
        "\t\t# repeat experiment\n",
        "\t\tscores = list()\n",
        "\t\tfor r in range(repeats):\n",
        "\t\t\tscore,my_model = evaluate_model(trainX, trainy, testX, testy, p)\n",
        "\t\t\tscore = score * 100.0\n",
        "\t\t\tprint('>p=%s #%d: %.3f' % (p, r+1, score))\n",
        "\t\t\tscores.append(score)\n",
        "\t\tall_scores.append(scores)\n",
        "\t# summarize results\n",
        "\tsummarize_results(all_scores, params)\n",
        "\treturn my_model\n",
        "\n",
        "# # run the experiment\n",
        "# n_params = [False, True]\n",
        "my_model = run_experiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdho6LLiWO1F"
      },
      "source": [
        "## Testing on the data sent by Reza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "z3czs3vwWSBd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "pd.options.mode.chained_assignment = None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.columns\n",
        "\n",
        "\n",
        "def tran(x):\n",
        "    y = x[1:-1]\n",
        "    return y.split(',')\n",
        "\n",
        "def data_wrangle( df ):\n",
        "    sample = df[['timestamp','raw_sensor_data']];\n",
        "    sample['parameters'] = sample.raw_sensor_data.apply(tran);\n",
        "    main = pd.DataFrame( sample.parameters.to_list() , columns = ['Time', 'Angle', 'ax', 'ay', 'az', 'gx', 'gy', 'gz', 'mx', 'my', 'mz'] );\n",
        "    main['timestamp'] = sample['timestamp'];\n",
        "    main.drop( 'Time' , axis = 1 , inplace = True );\n",
        "    main.set_index('timestamp' , inplace=True);\n",
        "    return main;\n",
        "\n",
        "def encapsule(df):\n",
        "    display(df.head(5))\n",
        "    print( f'shape of df = {df.shape}' )\n",
        "    return df\n",
        "\n",
        "def change_time(some_df):\n",
        "  some_df = some_df.reset_index()\n",
        "  #display(some_df.head(5))\n",
        "  some_df['timestamp'] = pd.to_datetime(some_df['timestamp'] , utc= True )\n",
        "  #display(some_df.dtypes)\n",
        "  some_df['timestamp'] = some_df['timestamp'].dt.tz_convert('Australia/Melbourne')\n",
        "  some_df.set_index('timestamp', inplace = True)\n",
        "  some_df[some_df.columns.drop('Activity')] = some_df[some_df.columns.drop('Activity')].applymap( pd.to_numeric )\n",
        "  return some_df    "
      ],
      "metadata": {
        "id": "qT7d25fIXENQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Rs7xd8OGWdD_"
      },
      "outputs": [],
      "source": [
        "Standing_df = encapsule(data_wrangle(pd.read_excel('/content/Sord_analysis/Activity_files/Standing.xlsx')))\n",
        "Standing_df.sort_index(inplace = True)\n",
        "\n",
        "walk1 = encapsule(data_wrangle(pd.read_excel('/content/Sord_analysis/Activity_files/Walking.xlsx')))\n",
        "walk1.sort_index(inplace = True)\n",
        "\n",
        "walk2 = encapsule(data_wrangle(pd.read_excel('/content/Sord_analysis/Activity_files/Walking2.xlsx')))\n",
        "walk2.sort_index(inplace = True)\n",
        "\n",
        "Sitting = encapsule(data_wrangle(pd.read_excel('/content/Sord_analysis/Activity_files/Sitting.xlsx')))\n",
        "Sitting.sort_index(inplace = True)\n",
        "\n",
        "\n",
        "\n",
        "Standing_df['Activity'] = 'Standing'\n",
        "walk1['Activity'] = 'Walking'\n",
        "walk2['Activity'] = 'Walking'\n",
        "Sitting['Activity'] = 'Sitting'\n",
        "\n",
        "combined = pd.concat([ Standing_df,walk1,walk2,Sitting ])\n",
        "\n",
        "\n",
        "combined.drop(combined.iloc[np.where( combined == '-' )[0] , 9].index, inplace=True)\n",
        "combined = change_time(combined)\n",
        "combined.Angle = (180 -  combined.Angle)\n",
        "\n",
        "\n",
        "combined = combined.sort_index()\n",
        "combined.Activity = combined.Activity.map( { 'Sitting':0  , 'Standing' : 1 , 'Walking' : 2   })\n",
        "reza_train , lebels  = create_segments_and_labels(combined ,  64 , 32)\n",
        "print(reza_train.shape)\n",
        "# print(lebels.shape)\n",
        "# lebels = to_categorical(lebels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = my_model.predict( reza_train )"
      ],
      "metadata": {
        "id": "UV9JRU3ZafEf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df  = pd.DataFrame(preds)\n",
        "preds_df.dropna( how = 'all' , inplace = True  )\n",
        "\n",
        "predds = []\n",
        "for i in  preds_df.index:\n",
        "   predds.append(np.argmax( preds_df.loc[i,] ))\n",
        "\n"
      ],
      "metadata": {
        "id": "NlzFZinbbyUb"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_preds = []\n",
        "for each in preds:\n",
        "    list_of_preds.append(np.argmax(each) )"
      ],
      "metadata": {
        "id": "aiHzc4vIaq5j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  collections import Counter\n",
        "print( 'Predictions := ' ,  Counter(lebels[preds_df.index]))\n",
        "\n",
        "print( 'Originale := ' , Counter(predds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dURxMDvxc0_b",
        "outputId": "1d39269b-2b45-44a4-9bb4-9dda0976de32"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions :=  Counter({0: 1399, 2: 507, 1: 473})\n",
            "Originale :=  Counter({0: 1346, 1: 528, 2: 505})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print( accuracy_score(  predds , lebels[preds_df.index]  ) * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QszjljjsbFzi",
        "outputId": "888fd84e-f78d-4812-8a0c-8259ffadaad1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97.6881042454813\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CCN_activity_recog.ipynb",
      "provenance": [],
      "mount_file_id": "1Ox80tyDhA9NpuFRlrs5Y-tCAPjTJ3aE2",
      "authorship_tag": "ABX9TyMyGE+BonPLAPRgMXFoRP2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}